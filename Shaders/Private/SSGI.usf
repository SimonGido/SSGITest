#include "/Engine/Public/Platform.ush"

RWTexture2D<float4> OutputTexture;
Texture2D<float4>   ColorTexture;
Texture2D<float4>   NormalTexture;
Texture2D<float>    DepthTexture;

SamplerState InputSampler
{
    Filter = MIN_MAG_LINEAR_MIP_POINT; // Bilinear filtering
    AddressU = Wrap; // Wrap addressing mode in U direction
    AddressV = Wrap; // Wrap addressing mode in V direction
};


float4x4 InverseProjection;
float4x4 InverseView;
float4x4 Projection;
float4x4 View;
float2   ViewportSize;
int      FrameCount;
int      StepCount;


float4 GetClipPosition(float2 coords, float depth)
{
    coords /= ViewportSize;
    return float4(coords.x * 2.0 - 1.0, coords.y * 2.0 - 1.0, depth * 2.0 - 1.0, 1.0f);
}


float3 GetViewPos(float2 coords, float depth)
{
    float4 clipPosition = GetClipPosition(coords, depth);
    float4 target = mul(clipPosition, InverseProjection);
    float3 viewPos = target.xyz / target.w;
    
    return viewPos;
}

float3 GetViewPos(float2 coords)
{
    float depth = DepthTexture[int2(coords)];
    float4 clipPosition = GetClipPosition(coords, depth);
    float4 target = mul(clipPosition, InverseProjection);
    float3 viewPos = target.xyz / target.w;
    
    return viewPos;
}

float3 GetViewNormal(float2 coords)
{
    float3 p1 = GetViewPos(coords + float2(1.0, 0.0)).xyz;
    float3 p2 = GetViewPos(coords + float2(0.0, 1.0)).xyz;
    float3 p3 = GetViewPos(coords + float2(-1.0, 0.0)).xyz;
    float3 p4 = GetViewPos(coords + float2(0.0, -1.0)).xyz;

    float3 vP = GetViewPos(coords);

    float3 dx = vP - p1;
    float3 dy = p2 - vP;
    float3 dx2 = p3 - vP;
    float3 dy2 = vP - p4;


    float2 uv = coords / ViewportSize.xy;
    float pW = 1.0 / ViewportSize.x;
    float pH = 1.0 / ViewportSize.y;


    if (length(dx2) < length(dx) && uv.x - pW >= 0.0 || uv.x + pW > 1.0)
    {
        dx = dx2;
    }

    if (length(dy2) < length(dy) && uv.y - pH >= 0.0 || uv.y + pH > 1.0)
    {
        dy = dy2;
    }

    return normalize(-cross(dx, dy).xyz);
}


float4 GetPixelWorldPosition(float2 coords, float depth)
{
    float3 viewPos = GetViewPos(coords, depth);
    
    // Return the world space position by transforming the view space position by the inverse view matrix
    float4 worldPosition = mul(float4(viewPos.xyz, 1.0f), InverseView);
    
    return worldPosition;
}

float IGN(float2 coord, int frameId)
{
	// magic values are found by experimentation
    coord += float(frameId) * (float2(47, 17) * 0.695f);

    float3 magic = float3(0.06711056f, 0.00583715f, 52.9829189f);
    
    //https://juejin.cn/post/6844903687505068045
    //vec3 magic = vec3( 12.9898, 78.233, 43758.5453123 );
    
    return frac(magic.z * frac(dot(coord, magic.xy)));
}


float2 GetUVFromWorldPos(float3 worldPos)
{
    float4 clipPos = mul(float4(worldPos, 1.0), Projection);
    float2 uv = clipPos.xy / clipPos.w;
    uv = 0.5 * uv + 0.5;
    return uv;
}

float3 GetPerpendicularVector(float3 vec)
{
    float3 absVector = abs(vec);
    float3 perpendicularVector;

    if (absVector.y >= 0.9f)
        perpendicularVector = float3(vec.z, vec.x, -vec.y);
    else
        perpendicularVector = float3(-vec.y, vec.z, vec.x);

    return normalize(perpendicularVector);
}

// Get a cosine-weighted random vector centered around a specified normal direction.
float3 GetCosHemisphereSample(float rand1, float rand2, float3 hitNorm)
{
	// Get 2 random numbers to select our sample with
    float2 randVal = float2(rand1, rand2);

	// Cosine weighted hemisphere sample from RNG
    float3 bitangent = GetPerpendicularVector(normalize(hitNorm));
    float3 tangent = cross(bitangent, hitNorm);
    float r = sqrt(randVal.x);
    float phi = 2.0f * 3.14159265f * randVal.y;

	// Get our cosine-weighted hemisphere lobe sample direction
    return tangent * (r * cos(phi).x) + bitangent * (r * sin(phi)) + hitNorm.xyz * sqrt(max(0.0, 1.0f - randVal.x));
}



struct RaymarchResult
{
    float2 UV;
    float Depth;
    bool Hit;
};

RaymarchResult Raymarch(float3 viewPos, float3 dir, int stepCount, float stepSize, float depth)
{
    float3 pos = viewPos;
    RaymarchResult result;
    result.Hit = false;
    
    for (int step = 0; step < stepCount; step++)
    {
        pos += dir * stepSize;
        float2 uv = GetUVFromWorldPos(pos);
        float2 pixel = uv * ViewportSize.xy;
        if (pixel.x > ViewportSize.x || pixel.y > ViewportSize.y)
            break;
        
        float sampledDepth = DepthTexture[int2(pixel)];
        if (depth < sampledDepth)
        {
            result.Hit = true;
            result.UV = uv;
            result.Depth = sampledDepth;
            break;
        }
    }
    return result;
}

RaymarchResult RaymarchClip(float3 origin, float3 dir, int stepCount, float stepSize, float depth)
{
    float3 pos = origin;
    RaymarchResult result;
    result.Hit = false;
    
    for (int step = 0; step < stepCount; step++)
    {
        pos += dir * stepSize;
        float2 uv = (pos.xy + 1.0) * 0.5;
        float2 pixel = uv * ViewportSize.xy;
        if (pixel.x > ViewportSize.x || pixel.y > ViewportSize.y || pixel.x < 0.0f || pixel.y < 0.0f)
            break;
        
        float sampledDepth = DepthTexture[int2(pixel)];
        
        if (depth < sampledDepth)
        {
            result.Hit = true;
            result.UV = uv;
            result.Depth = sampledDepth;
            break;
        }
    }   
    return result;
}


//float4 TestClipDir() // TODO: this is probably proper way to calculate clip dir
//{
//    float3 clipDir = mul(viewDir, (float3x3) View);
//    float4 clipNormal = mul(float4(clipDir, 0.0), Projection);
//    clipNormal.xyz /= clipNormal.w;
//    clipNormal.xyz = normalize(clipNormal.xyz);
//    clipDir = clipNormal.xyz;
//}


[numthreads(THREADGROUPSIZE_X, THREADGROUPSIZE_Y, THREADGROUPSIZE_Z)]
void Main(uint3 Gid : SV_GroupID, //atm: -, 0...256, - in rows (Y)        --> current group index (dispatched by c++)
                       uint3 DTid : SV_DispatchThreadID, //atm: 0...256 in rows & columns (XY)   --> "global" thread id
                       uint3 GTid : SV_GroupThreadID, //atm: 0...256, -,- in columns (X)      --> current threadId in group / "local" threadId
                       uint GI : SV_GroupIndex)            //atm: 0...256 in columns (X)           --> "flattened" index of a thread within a group)
{

    if (DTid.x >= int(ViewportSize.x) || DTid.y >= int(ViewportSize.y))
        return;
    
    int2 coords = DTid.xy;
    float2 uv = float2(coords.xy) / ViewportSize.xy;
    
    
    float noiseX = IGN(float2(coords), coords.x); //Animated Interleaved Gradient Noise
    float noiseY = IGN(float2(coords), coords.y); //Animated Interleaved Gradient Noise
    float stepSize = 1.0 / float(StepCount);
    stepSize = stepSize * (noiseX + noiseY) + stepSize + 0.5f;
   
    float depth = DepthTexture[coords.xy];
    // Fragment world position
    float3 worldPos = GetPixelWorldPosition(float2(coords.xy), depth).xyz;
    float3 clipPosition = GetClipPosition(float2(coords.xy), depth).xyz;
    float3 viewPos = GetViewPos(float2(coords.xy), depth);
    float3 screenPos = float3(coords.x, coords.y, depth);
    float3 normal = normalize(NormalTexture.SampleLevel(InputSampler, uv, 0).rgb);
    
    float3 viewDir = normalize(GetCosHemisphereSample(noiseX, noiseY, normal));

    
    float3 clipDir = normalize(mul(float4(viewDir, 1.0f), View)).xyz;
    clipDir = normalize(mul(float4(clipDir, 1.0), Projection)).xyz;
    
  
    // TODO: find out what is actually ray origin... and how to sample color while raymarching
    //RaymarchResult raymarchResult = Raymarch(worldPos, viewDir, stepCount, stepSize, depth);
    RaymarchResult raymarchResult = RaymarchClip(clipPosition, clipDir, StepCount, stepSize, depth);
    
    float4 sampledColor = ColorTexture[int2(raymarchResult.UV * ViewportSize.xy)];
    float4 origColor = ColorTexture[coords.xy];
    
    if (!raymarchResult.Hit || depth == 0.0f)
        sampledColor = float4(0.0f, 0.0f, 0.0f, 0.0f);

    OutputTexture[coords.xy] = sampledColor;
    //OutputTexture[coords.xy] = float4(normal, 1.0f);
    //OutputTexture[coords.xy] = float4(depth, depth, depth, 1.0f);
    
}